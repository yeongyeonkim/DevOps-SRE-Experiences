### 목적

Prometheus 메모리 및 디스크 사용량 절감

Scrape 및 Query 응답속도 향상

불필요한 시계열 정리 및 Metric 품질 표준화

장기적으로 관찰성(Observability) 표준화 체계 구축

### 문제 원인 분석 및 개선 포인트

#### 1. 새로운 알람(RDS) 설정

![dmllatencyquery](img/dmllatencyquery.png)

10월 15일 RDS DMLLatency Alert 설정을 진행하였다.

다음 날 추이를 확인해보니 급격하게 시계열, 리소스 사용량 등 증가하는 모습이 보였다.

![prometheustsdb1014](img/prometheustsdb(1014).png)

* 10/14 09:00 
    * numSeries: 390k
    * memory: 1832Mi

![prometheustsdb1016](img/prometheustsdb(1016).png)

* 10/16 08:30
    * numSeries: 458k
    * memory: 2063Mi

![prometheusoverview](img/prometheusoverview.png)

#### 개선 포인트 확인

* Grafana Alert 생성으로 CloudWatch query가 RDS별로 세분화되어
  Prometheus에서 새로운 시계열이 대량 생성되었다.
  이는, 일시적인 spike가 아닌 cardinality 증가임

* maxDataPoints 43200 -> 1440(1일 기준) 이하로 축소?
* discovery 간격 조정 (scrape_interval 5분 이상)
* metric_relabel_configs를 통해 불필요한 label 제거
* 필요 시, remote_wrtie to Thanos/Mimir 구조 고려 (cardinality offload)

#### 2. 순간적으로 상승하는 시계열

![IncreaseTimeSeries](img/IncreaseTimeSeries.png)

#### 3. 급증하는 리소스

![prometheusShutDownAfterPromQL](img/prometheusShutDownAfterPromQL.png)

Heatmap 패널 및 알람을 구성하기 위해 위와 같은 쿼리를 테스트 환경에서 실행시켜보았다.

CPU 2core, Memory 4Gi 되어있는 프로메테우스 Statefulset은 CPU, Memory 사용률을 100%로 사용하고 죽어버렸다.

### 개선 작업

#### 1. High Cardinality 개선

다른 페이지에서 설명









### 성과 및 결과


