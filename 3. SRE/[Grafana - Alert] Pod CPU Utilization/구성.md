### 목표

* Pod 별 CPU Utilization이 60%, 80% 넘는 경우 각각 Warning, Critical 알림을 받는다.

* Prometheus Rule이 구성에는 더 쉽겠지만.. 팀 내부적인 이유로 Grafana Alert rule을 활용해본다.


### 최종 쿼리 및 설명

```
# Query A (CPU + 생성시간)
(
  rate(container_cpu_usage_seconds_total{namespace=~"$namespace", container!="POD", container!=""}[1m])
  /
  on(pod, namespace, container) group_left()
  kube_pod_container_resource_requests{resource="cpu", namespace=~"$sp_namespace"}
  * 100
) >= 60
and on(pod, namespace)
(
  (time() - kube_pod_created{}) > 600
)
```

<b>Options</b>
 - Time Range: now-5m to now
 - Interval: 30s

 
 * ※ 대부분의 Query의 결과는 time series인데, Grafana에서 Alert rule을 생성할 때 time series로의 threshold를 Alert condition 으로 두려고하면 `You cannot use time series data as an alert condition, consider adding a reduce expression.` 에러가 발생한다. 
 * 따라서 time series 데이터를 단일 값으로 변환하는 reduce expression을 추가해야 한다. Grafana에서는 시계열 데이터의 여러 데이터 포인트를 하나의 값으로 집계해야만 threshold와 비교할 수 있기 때문이다.
 * 근데 이제 이 reduce가 감지하는 범위가 넓은 범위로 인한 Time Range에 걸리면 Firing이 계속 유지되는 경험을 할 수 있다.

<b>Evaluation behavior</b>
 - evaluated every 30s (더 빠른 감지)
 - Pending period 0s (즉시 알림)

<b>[트리거 조건]</b>
알림이 발생하는 조건:
컨테이너의 CPU 사용률이 60%, 80%를 초과하고, 해당 파드가 생성된 지 10분(600초) 이상 경과한 경우

<b>[평가 주기]</b>
매 30초마다 조건 평가
조건 충족 시 즉시 알림 발생 (Pending 기간 없음)

<b>[데이터 수집 범위]</b>
최근 5분간의 데이터를 30초 간격으로 수집하여 평가

### Grafana Alert rule 설정

1. Notification Template

![2](img/2.png)

```
{{ define "title-pod-cpu" }}
  [{{ .CommonLabels.severity | title }}][Pod][CPU] - {{ .Status | title }}
{{ end }}
```

```
{{ define "message-pod-cpu" }}
{{- $a := index .Alerts 0 -}}

{{ range .Alerts }}
**{{ .Labels.pod }}**
- **Namespace:** {{ .Labels.namespace }}
- **Node:** {{ .Labels.node }}
{{ end }}
**발생 시점** 
- {{ $a.StartsAt | tz "Asia/Seoul" | date "2006-01-02 15:04:05 KST" }}

**요약**
- {{ if eq $a.Labels.severity "Warning" }}1분간 CPU 사용량 60% 초과{{ else if eq $a.Labels.severity "Critical" }}1분간 CPU 사용량 80% 초과{{ else }}CPU 사용량 임계값 초과{{ end }}

**조치 방법**
- 
{{ end }}
```

2. Microsoft Teams 설정

![3](img/3.png)

3. K6를 통한 부하 및 결과 확인

![4](img/4.png)

![5](img/5.png)

4. 추가로 노이즈 제거

![crashloopbackoff](img/crashloopbackoff.png)
* CPU 사용량과 Pod 생성 시간 두 조건만으로 충분할 것이라 생각했지만 CrashLoopBackOff로 파드가 재기동되고 SpringBoot가 부트 구동 시, 초기화를 하는 과정에서 튀는 CPU를 고려하지 못했어서 노이즈가 발생했다.

* 때문에 Pod 상태 값에 따른 알람을 설정한 뒤, CPU Utilization 쿼리에서는 노이즈를 제거하는 쿼리 개선이나 설정 변경이 필요하다.
